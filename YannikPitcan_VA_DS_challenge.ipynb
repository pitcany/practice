{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5bac81",
   "metadata": {},
   "source": [
    "\n",
    "# Sampling Bias Correction in TV Viewer Data\n",
    "\n",
    "## Introduction\n",
    "In this analysis, we address the problem of sampling bias in a dataset of TV viewers. The dataset is a biased sample from a universe of television-watching individuals, with certain demographic categories being over– or under–represented. Our goal is to calculate a set of person–level weights that unbias the dataset.\n",
    "\n",
    "## Data Loading and Initial Exploration\n",
    "First, we load the 'demographic attributes.csv' and 'demo ground truth.csv' datasets and explore their structure and content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791e89c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   person id     age        education ethnicity\n",
       " 0          0   75_84     Some College     white\n",
       " 1          1  85_120       HS Diploma     white\n",
       " 2          2   25_34     Some College     white\n",
       " 3          3   55_64       HS Diploma     black\n",
       " 4          4   45_54  Bachelor Degree     white,\n",
       "   demographic category  number of individuals\n",
       " 0                18_24               11839159\n",
       " 1                25_34               16399632\n",
       " 2                35_44               15335704\n",
       " 3                45_54               16430762\n",
       " 4                55_64               15148777)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Load the datasets\n",
    "demographic_attributes = pd.read_csv('/Users/yannik/Projects/VideoAmp/demographic_attributes.csv')\n",
    "demo_ground_truth = pd.read_csv('/Users/yannik/Projects/VideoAmp/demo_ground_truth_csv.csv')\n",
    "\n",
    "# Show the first few rows of each dataset\n",
    "demographic_attributes.head(), demo_ground_truth.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0434e6",
   "metadata": {},
   "source": [
    "\n",
    "## Data Cleaning and Validation\n",
    "Next, we check for missing values and validate the consistency of demographic categories between the two datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6029d19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(person id        0\n",
       " age              0\n",
       " education    22190\n",
       " ethnicity        0\n",
       " dtype: int64,\n",
       " demographic category     0\n",
       " number of individuals    0\n",
       " dtype: int64,\n",
       " array(['75_84', '85_120', '25_34', '55_64', '45_54', '18_24', '65_74',\n",
       "        '35_44'], dtype=object),\n",
       " array(['Some College', 'HS Diploma', 'Bachelor Degree', 'Graduate Degree',\n",
       "        'Unknown', '< Than HS Diploma'], dtype=object),\n",
       " array(['white', 'black', 'hispanic', 'asian', 'islander'], dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Checking for missing values in both datasets\n",
    "missing_values_demographic_attributes = demographic_attributes.isnull().sum()\n",
    "missing_values_demo_ground_truth = demo_ground_truth.isnull().sum()\n",
    "\n",
    "# Handling missing values in 'education' column by categorizing them as a separate category\n",
    "demographic_attributes['education'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Checking unique values in demographic categories to validate consistency\n",
    "unique_age = demographic_attributes['age'].unique()\n",
    "unique_education = demographic_attributes['education'].unique()\n",
    "unique_ethnicity = demographic_attributes['ethnicity'].unique()\n",
    "\n",
    "missing_values_demographic_attributes, missing_values_demo_ground_truth, unique_age, unique_education, unique_ethnicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f1afb",
   "metadata": {},
   "source": [
    "\n",
    "## Data Cleaning and Validation\n",
    "Next, we check for missing values and validate the consistency of demographic categories between the two datasets.\n",
    "\n",
    "### Missing Values\n",
    "We'll identify and handle any missing values in our datasets to ensure the quality of our analysis. I chose to redistribute individuals in the 'Unknown' category proportionally based on the distribution of known education levels. This would eliminate the 'Unknown' category from the data, resolving missing data issues.\n",
    "\n",
    "### Consistency of Demographic Categories\n",
    "We'll also check that the demographic categories in our sample dataset are consistent with the categories in the ground truth dataset, to ensure that our analysis is based on a correct understanding of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8716dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person id</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>75_84</td>\n",
       "      <td>Some College</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85_120</td>\n",
       "      <td>HS Diploma</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25_34</td>\n",
       "      <td>Some College</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>55_64</td>\n",
       "      <td>HS Diploma</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>45_54</td>\n",
       "      <td>Bachelor Degree</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person id     age        education ethnicity\n",
       "0          0   75_84     Some College     white\n",
       "1          1  85_120       HS Diploma     white\n",
       "2          2   25_34     Some College     white\n",
       "3          3   55_64       HS Diploma     black\n",
       "4          4   45_54  Bachelor Degree     white"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Identify 'Unknown' individuals\n",
    "unknown_education_mask = demographic_attributes['education'] == 'Unknown'\n",
    "\n",
    "# Step 2: Calculate distribution of known education levels\n",
    "known_education_distribution = demographic_attributes[~unknown_education_mask]['education'].value_counts(normalize=True)\n",
    "\n",
    "# Step 3: Redistribute 'Unknown' individuals\n",
    "np.random.seed(42)  # For reproducibility\n",
    "redistributed_education = np.random.choice(known_education_distribution.index, size=unknown_education_mask.sum(), p=known_education_distribution.values)\n",
    "\n",
    "# Step 4: Update the dataset\n",
    "demographic_attributes.loc[unknown_education_mask, 'education'] = redistributed_education\n",
    "\n",
    "# Check the first few rows of the dataset to verify the changes\n",
    "demographic_attributes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a55c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculating the observed proportions in the sampled dataset (Us)\n",
    "age_distribution_sampled = demographic_attributes['age'].value_counts(normalize=True)\n",
    "education_distribution_sampled = demographic_attributes['education'].value_counts(normalize=True)\n",
    "ethnicity_distribution_sampled = demographic_attributes['ethnicity'].value_counts(normalize=True)\n",
    "\n",
    "# Calculating the ground truth proportions in the national population (U)\n",
    "total_individuals_national = demo_ground_truth['number of individuals'].sum()\n",
    "ground_truth_proportions = demo_ground_truth.set_index('demographic category')\n",
    "ground_truth_proportions['proportion'] = ground_truth_proportions['number of individuals'] / total_individuals_national\n",
    "\n",
    "# Separating the proportions by demographic category type (age, education, ethnicity)\n",
    "age_categories = ['18_24', '25_34', '35_44', '45_54', '55_64', '65_74', '75_84', '85_120']\n",
    "education_categories = ['< Than HS Diploma', 'HS Diploma', 'Some College', 'Bachelor Degree', 'Graduate Degree']\n",
    "ethnicity_categories = ['white', 'hispanic', 'black', 'asian', 'islander']\n",
    "\n",
    "age_proportions_national = ground_truth_proportions.loc[age_categories]['proportion']\n",
    "education_proportions_national = ground_truth_proportions.loc[education_categories]['proportion']\n",
    "ethnicity_proportions_national = ground_truth_proportions.loc[ethnicity_categories]['proportion']\n",
    "\n",
    "# Calculating the weights for each individual in the sampled dataset\n",
    "demographic_attributes['age_weight'] = demographic_attributes['age'].map(lambda x: age_proportions_national[x] / age_distribution_sampled[x])\n",
    "demographic_attributes['education_weight'] = demographic_attributes['education'].map(lambda x: education_proportions_national[x] / education_distribution_sampled[x])\n",
    "demographic_attributes['ethnicity_weight'] = demographic_attributes['ethnicity'].map(lambda x: ethnicity_proportions_national[x] / ethnicity_distribution_sampled[x])\n",
    "\n",
    "# Calculating the overall weight for each individual (product of age, education, and ethnicity weights)\n",
    "demographic_attributes['overall_weight'] = demographic_attributes['age_weight'] * demographic_attributes['education_weight'] * demographic_attributes['ethnicity_weight']\n",
    "\n",
    "# Normalizing the weights\n",
    "sum_overall_weights = demographic_attributes['overall_weight'].sum()\n",
    "normalization_factor = total_individuals_national / sum_overall_weights\n",
    "demographic_attributes['normalized_weight'] = demographic_attributes['overall_weight'] * normalization_factor\n",
    "\n",
    "# Verifying that the sum of normalized weights equals the total number of individuals in the national population\n",
    "sum_normalized_weights = demographic_attributes['normalized_weight'].sum()\n",
    "#print(sum_normalized_weights, total_individuals_national)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e492be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#age_proportions_national.head()\n",
    "#demographic_attributes['age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748745b",
   "metadata": {},
   "source": [
    "\n",
    "## Calculate Sampling Weights\n",
    "In this section, we calculate the sampling weights for each individual in the sampled dataset. The weights are calculated based on the discrepancies between the observed proportions in the sampled dataset (Us) and the ground truth proportions in the national population (U) for age, education, and ethnicity.\n",
    "\n",
    "### Steps:\n",
    "1. **Calculate Observed Proportions**: Compute the distribution of each demographic category in the sampled dataset.\n",
    "2. **Calculate Ground Truth Proportions**: Using the 'demo ground truth.csv' file, calculate the proportion of each demographic category in the national population.\n",
    "3. **Calculate Initial Weights**: For each individual, calculate weights for age, education, and ethnicity based on the ratio of ground truth to observed proportions.\n",
    "4. **Calculate Overall Weights**: Multiply the age, education, and ethnicity weights together to get an overall weight for each individual.\n",
    "5. **Normalize Weights**: Adjust the weights so that their sum equals the total number of individuals in the national population, ensuring that the weighted sampled dataset is representative of the national population.\n",
    "\n",
    "This process helps to correct for sampling bias in the dataset, making it more representative of the national population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "070b58e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person id</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>age_weight</th>\n",
       "      <th>education_weight</th>\n",
       "      <th>ethnicity_weight</th>\n",
       "      <th>overall_weight</th>\n",
       "      <th>normalized_weight</th>\n",
       "      <th>raked_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>75_84</td>\n",
       "      <td>Some College</td>\n",
       "      <td>white</td>\n",
       "      <td>0.197185</td>\n",
       "      <td>0.313308</td>\n",
       "      <td>0.290993</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>516.925692</td>\n",
       "      <td>423.634924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85_120</td>\n",
       "      <td>HS Diploma</td>\n",
       "      <td>white</td>\n",
       "      <td>0.245415</td>\n",
       "      <td>0.266008</td>\n",
       "      <td>0.290993</td>\n",
       "      <td>0.018997</td>\n",
       "      <td>546.232925</td>\n",
       "      <td>622.333438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25_34</td>\n",
       "      <td>Some College</td>\n",
       "      <td>white</td>\n",
       "      <td>0.837213</td>\n",
       "      <td>0.313308</td>\n",
       "      <td>0.290993</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>2194.777954</td>\n",
       "      <td>1851.716351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>55_64</td>\n",
       "      <td>HS Diploma</td>\n",
       "      <td>black</td>\n",
       "      <td>0.175287</td>\n",
       "      <td>0.266008</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>643.681720</td>\n",
       "      <td>736.878989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>45_54</td>\n",
       "      <td>Bachelor Degree</td>\n",
       "      <td>white</td>\n",
       "      <td>0.220188</td>\n",
       "      <td>0.222091</td>\n",
       "      <td>0.290993</td>\n",
       "      <td>0.014230</td>\n",
       "      <td>409.173739</td>\n",
       "      <td>450.725903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person id     age        education ethnicity  age_weight  education_weight  \\\n",
       "0          0   75_84     Some College     white    0.197185          0.313308   \n",
       "1          1  85_120       HS Diploma     white    0.245415          0.266008   \n",
       "2          2   25_34     Some College     white    0.837213          0.313308   \n",
       "3          3   55_64       HS Diploma     black    0.175287          0.266008   \n",
       "4          4   45_54  Bachelor Degree     white    0.220188          0.222091   \n",
       "\n",
       "   ethnicity_weight  overall_weight  normalized_weight  raked_weight  \n",
       "0          0.290993        0.017977         516.925692    423.634924  \n",
       "1          0.290993        0.018997         546.232925    622.333438  \n",
       "2          0.290993        0.076329        2194.777954   1851.716351  \n",
       "3          0.480094        0.022386         643.681720    736.878989  \n",
       "4          0.290993        0.014230         409.173739    450.725903  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Optimized raking function\n",
    "def rake_optimized(weights, variable, demographic_data, ground_truth_series):\n",
    "    # Calculating the weighted distribution for the current variable\n",
    "    categories = demographic_data[variable].unique()\n",
    "    weighted_distribution = pd.Series(index=categories, dtype='float64')\n",
    "    for category in categories:\n",
    "        mask = demographic_data[variable] == category\n",
    "        weighted_distribution[category] = weights[mask].sum() / weights.sum()\n",
    "    \n",
    "    # Calculating the raking ratio\n",
    "    raking_ratio = ground_truth_series / weighted_distribution\n",
    "    raking_ratio = raking_ratio.fillna(1)  # Replace NaN with 1 for categories with no samples\n",
    "    \n",
    "    # Adjusting the weights\n",
    "    adjusted_weights = weights.copy()\n",
    "    for category in categories:\n",
    "        mask = demographic_data[variable] == category\n",
    "        adjusted_weights[mask] *= raking_ratio[category]\n",
    "    \n",
    "    return adjusted_weights\n",
    "\n",
    "# Initializing weights with the normalized weights\n",
    "raked_weights = demographic_attributes['normalized_weight'].copy()\n",
    "\n",
    "# Setting a threshold for convergence\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "# Performing raking until convergence\n",
    "while True:\n",
    "    # Previous weights\n",
    "    prev_weights = raked_weights.copy()\n",
    "    \n",
    "    # Raking for 'age'\n",
    "    raked_weights = rake_optimized(raked_weights, 'age', demographic_attributes, age_proportions_national)\n",
    "    \n",
    "    # Raking for 'education'\n",
    "    raked_weights = rake_optimized(raked_weights, 'education', demographic_attributes, education_proportions_national)\n",
    "    \n",
    "    # Raking for 'ethnicity'\n",
    "    raked_weights = rake_optimized(raked_weights, 'ethnicity', demographic_attributes, ethnicity_proportions_national)\n",
    "    \n",
    "    # Checking for convergence\n",
    "    if np.abs(raked_weights - prev_weights).sum() < convergence_threshold:\n",
    "        break\n",
    "\n",
    "# Normalizing the raked weights\n",
    "raked_weights = normalize(raked_weights.values.reshape(1, -1), norm='l1') * total_individuals_national\n",
    "raked_weights = raked_weights.flatten()\n",
    "\n",
    "# Adding the raked weights to the dataset\n",
    "demographic_attributes['raked_weight'] = raked_weights\n",
    "\n",
    "# Checking the first few rows of the dataset with the raked weights\n",
    "demographic_attributes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a510d49",
   "metadata": {},
   "source": [
    "\n",
    "## Validation\n",
    "In this section, we validate that the weighted distribution of demographic categories in the sampled dataset now matches the ground truth distribution. This is a crucial step to ensure that our weighting procedure has been successful in correcting the sampling bias.\n",
    "\n",
    "### Steps:\n",
    "1. **Calculate Weighted Distribution**: Using the normalized weights, calculate the weighted distribution of each demographic category in the sampled dataset.\n",
    "2. **Compare with Ground Truth**: Compare the weighted distribution with the ground truth distribution to ensure that they are closely aligned.\n",
    "\n",
    "A successful validation indicates that our sampling weights have effectively adjusted the sampled dataset to be representative of the national population, mitigating the effects of sampling bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36db4eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Comparison:\n",
      "         Weighted  Ground Truth\n",
      "18_24   0.127771      0.035888\n",
      "25_34   0.176989      0.049712\n",
      "35_44   0.165507      0.046487\n",
      "45_54   0.177325      0.049806\n",
      "55_64   0.163489      0.045920\n",
      "65_74   0.107819      0.030284\n",
      "75_84   0.056351      0.015828\n",
      "85_120  0.024749      0.006951\n",
      "\n",
      "Education Comparison:\n",
      "                    Weighted  Ground Truth\n",
      "< Than HS Diploma  0.132464      0.037206\n",
      "Bachelor Degree    0.175975      0.049427\n",
      "Graduate Degree    0.100834      0.028322\n",
      "HS Diploma         0.278429      0.078204\n",
      "Some College       0.312297      0.087716\n",
      "\n",
      "Ethnicity Comparison:\n",
      "           Weighted  Ground Truth\n",
      "asian     0.052633      0.018628\n",
      "black     0.125276      0.044337\n",
      "hispanic  0.188032      0.066547\n",
      "islander  0.001631      0.000577\n",
      "white     0.632427      0.223823\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming demographic_attributes is your DataFrame and it has a column 'normalized_weight' for the weights\n",
    "# Also assuming demo_ground_truth is your ground truth DataFrame\n",
    "\n",
    "# 1. Calculate Weighted Distribution\n",
    "weighted_age_distribution = demographic_attributes.groupby('age').apply(lambda x: (x['raked_weight']).sum()) / demographic_attributes['raked_weight'].sum()\n",
    "weighted_education_distribution = demographic_attributes.groupby('education').apply(lambda x: (x['raked_weight']).sum()) / demographic_attributes['raked_weight'].sum()\n",
    "weighted_ethnicity_distribution = demographic_attributes.groupby('ethnicity').apply(lambda x: (x['raked_weight']).sum()) / demographic_attributes['raked_weight'].sum()\n",
    "\n",
    "# 2. Compare with Ground Truth\n",
    "# Assuming ground truth distributions are stored in age_proportions_national, education_proportions_national, and ethnicity_proportions_national\n",
    "\n",
    "age_comparison = pd.DataFrame({'Weighted': weighted_age_distribution, 'Ground Truth': age_proportions_national})\n",
    "education_comparison = pd.DataFrame({'Weighted': weighted_education_distribution, 'Ground Truth': education_proportions_national})\n",
    "ethnicity_comparison = pd.DataFrame({'Weighted': weighted_ethnicity_distribution, 'Ground Truth': ethnicity_proportions_national})\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Age Comparison:\\n\", age_comparison)\n",
    "print(\"\\nEducation Comparison:\\n\", education_comparison)\n",
    "print(\"\\nEthnicity Comparison:\\n\", ethnicity_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a36f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
